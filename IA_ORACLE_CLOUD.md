# ü§ñ Mod√®les IA sur Oracle Cloud - Guide Complet

**Question** : Peut-on lancer des IA comme DeepSeek avec le serveur Oracle Cloud gratuit ?

**R√©ponse** : **OUI, plusieurs options disponibles !**

---

## üéØ Options Disponibles

### Option 1 : DeepSeek via Ollama (Local, Gratuit) ‚≠ê

**Avantages** :
- ‚úÖ **100% gratuit** - Pas besoin de cl√© API
- ‚úÖ **Local** - Fonctionne sur le serveur
- ‚úÖ **Sans limites** - Pas de quotas
- ‚úÖ **Priv√©** - Donn√©es restent sur le serveur

**Mod√®les DeepSeek disponibles via Ollama** :
- `deepseek-r1:1.5b` - Mod√®le l√©ger (1.5B param√®tres)
- `deepseek-r1:7b` - Mod√®le moyen (7B param√®tres)
- `deepseek-r1:14b` - Mod√®le complet (14B param√®tres)
- `deepseek-coder` - Sp√©cialis√© code
- `deepseek-chat` - Mod√®le conversationnel

**Besoins en RAM** :
- deepseek-r1:1.5b : ~2GB RAM
- deepseek-r1:7b : ~6-8GB RAM
- deepseek-r1:14b : ~14-16GB RAM

**Oracle Cloud ARM** : ‚úÖ Peut faire tourner jusqu'√† deepseek-r1:14b
**Oracle Cloud x86** : ‚ö†Ô∏è Seulement deepseek-r1:1.5b

---

### Option 2 : DeepSeek via API (N√©cessite Cl√©)

**Avantages** :
- ‚úÖ Mod√®les plus r√©cents
- ‚úÖ Meilleure performance
- ‚úÖ Pas de ressources serveur utilis√©es

**Limitations** :
- ‚ö†Ô∏è N√©cessite cl√© API DeepSeek
- ‚ö†Ô∏è Quotas/limites selon le plan
- ‚ö†Ô∏è Co√ªts possibles

**Configuration** :
```env
DEEPSEEK_API_KEY=your-api-key-here
```

---

## üöÄ Installation DeepSeek via Ollama

### Sur Oracle Cloud ARM (Recommand√©)

```bash
# 1. Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. T√©l√©charger DeepSeek (mod√®le 7B recommand√©)
ollama pull deepseek-r1:7b

# 3. Tester
ollama run deepseek-r1:7b "Hello, how are you?"

# 4. Configurer dans .env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b
```

**R√©sultat** : ‚úÖ **Totalement op√©rationnel**

### Sur Oracle Cloud x86 (Limit√©)

```bash
# 1. Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. T√©l√©charger seulement le mod√®le l√©ger
ollama pull deepseek-r1:1.5b

# 3. Configurer dans .env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:1.5b
```

**R√©sultat** : ‚úÖ **Op√©rationnel mais limit√© au mod√®le 1.5B**

---

## üìä Mod√®les IA Disponibles via Ollama

### Mod√®les Conversationnels

| Mod√®le | RAM Requise | Oracle ARM | Oracle x86 |
|--------|-------------|------------|------------|
| **deepseek-r1:1.5b** | 2GB | ‚úÖ OUI | ‚úÖ OUI |
| **deepseek-r1:7b** | 6-8GB | ‚úÖ OUI | ‚ùå NON |
| **deepseek-r1:14b** | 14-16GB | ‚úÖ OUI | ‚ùå NON |
| **llama3.2:1b** | 1-2GB | ‚úÖ OUI | ‚úÖ OUI |
| **llama3.2:3b** | 3-4GB | ‚úÖ OUI | ‚ùå NON |
| **llama3.1:8b** | 8-10GB | ‚úÖ OUI | ‚ùå NON |
| **mistral** | 4-6GB | ‚úÖ OUI | ‚ùå NON |
| **phi3** | 2-3GB | ‚úÖ OUI | ‚úÖ OUI |

### Mod√®les Sp√©cialis√©s

- **deepseek-coder** : Sp√©cialis√© code (6-8GB RAM)
- **codellama** : Code Llama (6-8GB RAM)
- **starcoder** : Code StarCoder (8-10GB RAM)

---

## üîß Configuration Compl√®te

### Configuration .env pour DeepSeek

```env
# Ollama (gratuit, local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b

# Ou DeepSeek API (si vous avez une cl√©)
DEEPSEEK_API_KEY=your-api-key-here

# Autres providers (optionnel)
GROQ_API_KEY=your-key
MISTRAL_API_KEY=your-key
GEMINI_API_KEY=your-key
```

### Le Backend Utilisera Automatiquement

1. **Ollama (DeepSeek)** si configur√© et disponible
2. **DeepSeek API** si cl√© API fournie
3. **Fallback** vers d'autres providers si n√©cessaire

---

## ‚úÖ Test de DeepSeek

### Test via Ollama

```bash
# Tester directement
ollama run deepseek-r1:7b "Explique-moi l'intelligence artificielle"

# Tester via le backend
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explique-moi l intelligence artificielle",
    "language": "fr"
  }'
```

### V√©rifier les Mod√®les Disponibles

```bash
# Lister les mod√®les Ollama install√©s
ollama list

# V√©rifier que DeepSeek est disponible
ollama list | grep deepseek
```

---

## üéØ Recommandations par Cas d'Usage

### Pour le D√©veloppement/Test

**Oracle Cloud ARM + DeepSeek 7B** :
- ‚úÖ Performance correcte
- ‚úÖ Gratuit
- ‚úÖ Suffisant pour tester

### Pour la Production (Test)

**Oracle Cloud ARM + DeepSeek 14B** :
- ‚úÖ Meilleure qualit√©
- ‚úÖ Gratuit
- ‚úÖ Parfait pour valider

### Pour la Production (Finale)

**VPS Payant (Hetzner) + DeepSeek API** :
- ‚úÖ Meilleure performance
- ‚úÖ Mod√®les plus r√©cents
- ‚úÖ Pas de ressources serveur utilis√©es

---

## üìã Checklist DeepSeek

### Installation
- [ ] Ollama install√© sur le serveur
- [ ] DeepSeek t√©l√©charg√© (deepseek-r1:7b recommand√©)
- [ ] Ollama fonctionne (test√© avec `ollama list`)

### Configuration
- [ ] .env configur√© avec OLLAMA_BASE_URL
- [ ] .env configur√© avec OLLAMA_MODEL=deepseek-r1:7b
- [ ] Backend red√©marr√©

### Test
- [ ] DeepSeek r√©pond via Ollama
- [ ] Backend utilise DeepSeek
- [ ] Chat fonctionne avec DeepSeek

---

## üÜö Comparaison DeepSeek vs Autres

### DeepSeek vs Llama

| Aspect | DeepSeek | Llama |
|--------|----------|-------|
| **Performance** | ‚úÖ Excellente | ‚úÖ Tr√®s bonne |
| **Disponibilit√© Ollama** | ‚úÖ OUI | ‚úÖ OUI |
| **Mod√®les disponibles** | 1.5B, 7B, 14B | 1B, 3B, 7B, 8B |
| **Sp√©cialisation code** | ‚úÖ OUI (deepseek-coder) | ‚úÖ OUI (codellama) |

### DeepSeek vs API Cloud

| Aspect | DeepSeek Ollama | DeepSeek API |
|--------|-----------------|--------------|
| **Co√ªt** | ‚úÖ Gratuit | ‚ö†Ô∏è Payant |
| **Performance** | ‚úÖ Bonne | ‚úÖ Excellente |
| **Ressources serveur** | ‚ö†Ô∏è Utilise RAM/CPU | ‚úÖ Pas de ressources |
| **Limites** | ‚úÖ Aucune | ‚ö†Ô∏è Quotas |

---

## üí° Astuces

### Optimiser DeepSeek sur Oracle Cloud

```bash
# Utiliser le mod√®le adapt√© √† la RAM disponible
# Oracle ARM (12GB RAM) : deepseek-r1:7b
# Oracle x86 (1GB RAM) : deepseek-r1:1.5b

# Limiter les ressources utilis√©es
export OLLAMA_NUM_GPU=0  # Pas de GPU
export OLLAMA_MAX_LOADED_MODELS=1  # Un seul mod√®le
```

### Utiliser Plusieurs Mod√®les

```bash
# T√©l√©charger plusieurs mod√®les
ollama pull deepseek-r1:7b
ollama pull llama3.2:3b
ollama pull mistral

# Changer dans .env selon les besoins
OLLAMA_MODEL=deepseek-r1:7b  # Pour code
OLLAMA_MODEL=llama3.2:3b     # Pour conversation
```

---

## ‚úÖ R√©ponse Finale

**OUI, vous pouvez lancer DeepSeek avec Oracle Cloud gratuit !**

### Oracle Cloud ARM
- ‚úÖ **Totalement op√©rationnel**
- ‚úÖ Peut faire tourner deepseek-r1:7b ou 14b
- ‚úÖ Performance correcte
- ‚úÖ Gratuit √† vie

### Oracle Cloud x86
- ‚úÖ **Op√©rationnel mais limit√©**
- ‚úÖ Seulement deepseek-r1:1.5b
- ‚ö†Ô∏è Performance limit√©e

### Alternatives
- ‚úÖ DeepSeek via API (si vous avez une cl√©)
- ‚úÖ Autres mod√®les Ollama (Llama, Mistral, etc.)

---

## üéØ Prochaines √âtapes

1. **Cr√©er instance Oracle Cloud ARM** (recommand√©)
2. **Installer Ollama**
3. **T√©l√©charger DeepSeek** : `ollama pull deepseek-r1:7b`
4. **Configurer .env** avec OLLAMA_MODEL=deepseek-r1:7b
5. **Tester** : Le backend utilisera automatiquement DeepSeek

---

**DeepSeek est totalement compatible avec Oracle Cloud gratuit ! üöÄ**

*Derni√®re mise √† jour : D√©cembre 2024*






